<!doctype html>
<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet" type="text/css">
<html lang="en-US">
    <head>
        <title>mini-midi.js</title>
        <link rel="stylesheet" type="text/css" href="main.css">
        <!-- <meta charset="UTF-8"> -->
    </head>
    <body>
        <br>
        <br>
        <div class="big">DIVING INTO MIDI<br></div>
        <br>

        <hr noshade><br>
        <!-- <br> -->
<!--         <div class="subhead">The first subheader<br></div>
        <br>
 -->
        Having had no prior experience with MIDI, and tasked with completing a project on the subject, I decided that the best way to gain familiarity was to do some programming. This is a quick demo of an application which produces MIDI output and interprets MIDI input to generate sound, and provides a visualization of the resulting waveform.<br>
        <br>
        This was made as part of a final project for Berkeley's Music 128, Spring 2016, with Professor Deirdre Loughridge.<br>
        <br>
        <div class="subhead">Design<br></div>
        <br>
        I wanted the entire application to run in the browser end-to-end with no external dependencies (software or hardware; I don't have access to a MIDI keyboard). Note that had I just wanted to design a synthesizer, MIDI would have been entirely unnecessary; as it is, this application doesn't rely on MIDI. It takes user input (using javascript event listeners), converts them into MIDI messages, and then passes the message as an argument to another javascript function which decodes the message and calls yet another javascript function to produce the appropriate output. The application will still function if you remove the MIDI encoding/decoding step and simply call the javascript functions directly. However, the advantage of having a MIDI translator in the code is that it would theoretically be possible for this application to work with a MIDI controller (as long as the MIDI data could properly be passed to the application, which is something I did not implement).<br>
        <br>
        <div class="subhead">Implementation<br></div>
        <br>
        The entire application is written in javascript. Since MIDI is just a standard for sending and receiving messages, it would be fairly bland without an actual audio source or synthesizer to interpret the messages and produce sound. I used the webaudio api's oscillators (which just produce several basic waveforms) as the main synthesis backend. I also implemented a Karplus-Strong string and percussion synthesizer (though admittedly the percussion sounds terrible). Note that since Karplus-Strong synthesis is more computationally intensive and generated live, there is a noticeable latency between user input and audio output. Even though MIDI itself is a compact protocol, its performance is ultimately limited by the abilities of the synthesizer it utilizes.<br>
        <br>
        The keyboard is tuned to equal-temperament using values along the Railsback curve. Notice that this was a choice made independently of the MIDI messages; that is, the MIDI data does not specify how the produced output should sound. This is because MIDI only transmits gestural and input data, leaving it to the synthesizer to decide how it should be interpreted.<br>
        <br>
        The MIDI standard specifies a large number of commands. The primitive audio synthesizers I used for this project are not terribly powerful, and I don't have enough of an understanding of signal processing to properly produce the effects of many of the MIDI messages. I therefore only implemented some basic commands: note on, note off, program change, and control (volume) change.<br>
        <br>
        <div id="wrapper">
            <br>
            <canvas id="visualization" width="640" height="480"></canvas><br>
            <div id="console-midi" class="scrollbox-midi"></div>
            <div id="console-js" class="scrollbox-js"></div>
            <script src="mini-midi.js"></script><br>
            <br>
            Demo MIDI synthesizer controlled with keyboard and mouse. Supports note on, note off, program change, control change; 4 oscillator programs and 2 Karplus-Strong synthesized programs. Output regarding volume is suppressed.<br>
            <br>

            <div class="blockbutton" title="View source on GitHub">
                <a href="https://github.com/brianxie/mini-midi">View source on GitHub</a><br>
            </div>
            <br>

        </div><br>
        <br>
        You can use your keyboard as a mock MIDI controller, since the application translates key commands into MIDI commands ("awsedftgyhujk" for keys, numeric keys (1-4, 8, 9) to change programs). The output volume corresponds to the vertical position of your mouse in the window (somewhat like a theremin). For the oscillators, the note will be held as long as the key is pressed down; the Karplus-Strong synthesizers don't support sustained notes, since they are designed to emulate string plucking.<br>
        <br>
        The application also produces some output; in the left box, you can see the MIDI message that was generated from your input. On the right, you can see a more human-readable description of what the synthesizer is doing. By default, all messages are shown except for volume change messages; these are generated each time your mouse moves, so printing these would result in lots of useless output, but they are happening in the background.<br>
        <br>
        <div class="subhead">Remarks<br></div>
        <br>
        MIDI presents a surprisingly simple interface. The messages are clear and concise, so they are easy to reason about and parse, and the messages map quite naturally to basic musical commands. I can see how it would be difficult to encode more complex and nuanced information with MIDI, but I imagine that that is a result of the intrinsic difficulty of precisely describing audio events and not the fault of MIDI itself.<br>
        <br>
        MIDI also opens up options for programmatic composing (which is an avenue that I chose not to explore). By recording MIDI messages (binary data) rather than actual sounds, one could compose a score, and easily make changes wherever necessary. For example, changing pitches or volumes would be equivalent to changing no more than 7 bits per note. While this paradigm may make it difficult to create extremely detailed or expressive audio, it excels at manipulating simple parameters.<br>
        <br>

        <hr noshade><br>

        <div class="big">References<br></div>
        <br>

        https://www.w3.org/TR/webaudio/<br>
        https://www.cs.cmu.edu/~music/cmsip/readings/MIDI%20tutorial%20for%20programmers.html<br>
        http://en.wikiaudio.org/MIDI:Channel_messages_tutorial<br>
        https://www.midi.org/specifications/item/table-1-summary-of-midi-message<br>
        https://en.wikipedia.org/wiki/Piano_acoustics#The_Railsback_curve<br>
        <br>


        <br>
    </body>
</html>

<!--         <div class="block">"If I had a quote, I would put it here."<br></div>
        <br>
 -->
